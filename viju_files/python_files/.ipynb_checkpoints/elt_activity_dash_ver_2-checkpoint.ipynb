{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:220\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(left, right)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py:131\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m _evaluate_standard(op, op_str, a, b)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 213\u001b[0m\n\u001b[1;32m    211\u001b[0m activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentered\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentered\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    212\u001b[0m activity_df \u001b[38;5;241m=\u001b[39m activity_df\u001b[38;5;241m.\u001b[39mmerge(watch_df, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 213\u001b[0m activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_watch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_time_watch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_time_entered\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    214\u001b[0m activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_watch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_watch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m    215\u001b[0m activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_watch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_watch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, activity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_watch\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39msub)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:5819\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   5818\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 5819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base\u001b[38;5;241m.\u001b[39mIndexOpsMixin\u001b[38;5;241m.\u001b[39m_arith_method(\u001b[38;5;28mself\u001b[39m, other, op)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:1381\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1378\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1381\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:285\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    281\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:229\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    223\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    224\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m         result \u001b[38;5;241m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 165\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import clickhouse_driver\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_columns', 250)\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "\n",
    "# with open('../clickhouse_connection-superset.json', 'r') as file:\n",
    "#     connection_data = json.load(file)\n",
    "    \n",
    "# host, dbname, user, password, port = connection_data['host'], connection_data['dbname'],\\\n",
    "#     connection_data['user'], connection_data['password'], connection_data['port']   \n",
    "\n",
    "con = create_engine(\"clickhouse://superset:FmnaRL3cC6wnTkn@10.129.11.136:8123/superset\")\n",
    "con.connect()\n",
    "\n",
    "\n",
    "def get_subs(date, df):\n",
    "    \"\"\"Возвращает список подписчиков user_id на дату\"\"\"\n",
    "\n",
    "    date = pd.to_datetime(date)\n",
    "    empty_date = pd.Timestamp('1970-01-01')\n",
    "\n",
    "    mask0 = pd.to_datetime(df['first_prolong_date']) > empty_date  # не пусто\n",
    "    mask1 = pd.to_datetime(df['first_prolong_date']) <= date\n",
    "    mask2 = pd.to_datetime(df['ends_at']) >= date\n",
    "\n",
    "    return df['user_id'][mask0 & mask1 & mask2].unique()\n",
    "\n",
    "def get_trials(date, df):\n",
    "    \"\"\"Возвращает список триалов user_id на дату\"\"\"\n",
    "    date = pd.to_datetime(date)\n",
    "\n",
    "    empty_date = pd.Timestamp('1970-01-01')\n",
    "\n",
    "    mask0 = pd.to_datetime(df['created_at']) > empty_date  # не пусто\n",
    "    mask1 = pd.to_datetime(df['created_at']) <= date\n",
    "    mask2 = pd.to_datetime(df['ends_at']) >= date\n",
    "    mask3 = (\n",
    "        (pd.to_datetime(df['first_prolong_date']) == empty_date) |\n",
    "        (pd.to_datetime(df['first_prolong_date']) > date)\n",
    "    )\n",
    "\n",
    "    return df['user_id'][mask0 & mask1 & mask2 & mask3].unique()\n",
    "\n",
    "def determine_status(row, df, status_df):\n",
    "    \"\"\"Возвращает датасет с updated user_id подписчиками и триалами на дату\"\"\"\n",
    "\n",
    "    date = pd.to_datetime(row['date']) # определенная дата\n",
    "    users_subs = get_subs(date, df) # список подписчиков\n",
    "    users_trial = get_trials(date, df) # список триалов\n",
    "\n",
    "    users_subs_df = pd.DataFrame({'user_id': users_subs, \n",
    "        'status': ['sub'] * len(users_subs), \n",
    "        'date': [date] * len(users_subs)}\n",
    "    ) # датасет подписчиков\n",
    "    \n",
    "    users_trial_df = pd.DataFrame({'user_id': users_trial, \n",
    "        'status': ['trial'] * len(users_trial), \n",
    "        'date': [date] * len(users_trial)}\n",
    "    ) # датасет триалов\n",
    "\n",
    "    return pd.concat([status_df, users_subs_df, users_trial_df])\n",
    "\n",
    "\n",
    "def get_cohort(row):\n",
    "    if row['promo_type'] == 'cards':\n",
    "        return 'cards'\n",
    "\n",
    "    promo_type, offer_duration, ub_type = row['promo_type'], row['offer_duration'], row['ub_type']\n",
    "    if promo_type == 'promo':\n",
    "        if offer_duration in ('1 month', '30 day'):\n",
    "            return 'promo_1m'\n",
    "        elif offer_duration == '3 month':\n",
    "            return 'promo_3m'\n",
    "        elif offer_duration in ('6 month', '200 day'):\n",
    "            return 'promo_6m'\n",
    "        elif offer_duration == '12 month':\n",
    "            return 'promo_12m'\n",
    "\n",
    "    elif promo_type == 'no_promo':\n",
    "        if ub_type in ['UserReferralBonus', 'UserInvitationBonus']:\n",
    "            return 'promo_1m'\n",
    "        elif offer_duration in ('1 month', '30 day'):\n",
    "            return 'organic_1m'\n",
    "        elif offer_duration == '3 month':\n",
    "            return 'organic_3m'\n",
    "        elif offer_duration == '6 month':\n",
    "            return 'organic_6m'\n",
    "        elif offer_duration == '12 month':\n",
    "            return 'organic_12m'\n",
    "\n",
    "    return 'other'\n",
    "\n",
    "\n",
    "def preprocess_users(df, cards=False):\n",
    "    \"\"\"Добавляет неделю и год к дате\"\"\"\n",
    "\n",
    "    df['user_id'] = df['user_id'].astype(str)\n",
    "    df['cohort'] = df.apply(get_cohort, axis=1)\n",
    "    if not cards:\n",
    "        df = df[df['cohort'] != 'cards'] # оставляем только B2C\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_watching(df):    \n",
    "    df['user_id'] = df['user_id'].astype(str)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    df.loc[df['event'] == 'kinom', 'minutes'] = df.loc[df['event'] == 'kinom', 'minutes'].clip(upper=60)\n",
    "    df.loc[df['event'] == 'tv', 'minutes'] = df.loc[df['event'] == 'tv', 'minutes'].clip(upper=120)\n",
    "    df.loc[df['event'] == 'series', 'minutes'] = df.loc[df['event'] == 'series', 'minutes'].clip(upper=120)\n",
    "    df.loc[df['event'] == 'movie', 'minutes'] = df.loc[df['event'] == 'movie', 'minutes'].clip(upper=120)\n",
    "\n",
    "    df = df[df['minutes'] > 5]\n",
    "\n",
    "    return df\n",
    "\n",
    "# загружаем всех пользователей с подпиской и триалом\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    user_id, toDate(created_at) AS created_at, \n",
    "    CASE \n",
    "        WHEN toDate(first_prolong_date) != '1970-01-01'\n",
    "        THEN toDate(first_prolong_date) - INTERVAL '1 day'\n",
    "        ELSE toDate(ends_at)  \n",
    "    END AS end_trial,\n",
    "    toDate(ends_at) AS ends_at,\n",
    "    toDate(first_prolong_date) AS first_prolong_date,\n",
    "    promo_type, offer_duration, ub_type\n",
    "FROM datamarts.marketing_dash_distr\n",
    "WHERE created_at != '1970-01-01'\n",
    "    AND ends_at > '2022-01-01'\n",
    "    AND (\n",
    "        (first_prolong_date > created_at) OR first_prolong_date = '1970-01-01'\n",
    "        )\n",
    "\"\"\"\n",
    "users_df = pd.read_sql(query, con=con)\n",
    "users_df = preprocess_users(users_df, cards=False)\n",
    "\n",
    "# список дат \n",
    "start_date = datetime(2023, 9, 6)\n",
    "end_date = datetime.now() - timedelta(days=1)\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "dates_df = pd.DataFrame(date_range, columns=['date'])\n",
    "\n",
    "# пользователи со статусом\n",
    "status_df = pd.DataFrame()\n",
    "for index, row in dates_df.iterrows():\n",
    "    status_df = determine_status(row, df=users_df, status_df=status_df)\n",
    "status_df = status_df.merge(users_df[['user_id', 'cohort', 'created_at', 'end_trial']])\n",
    "status_df = status_df[['date', 'user_id', 'cohort', 'status', 'created_at', 'end_trial']]\n",
    "status_df.head()\n",
    "\n",
    "# загружаем всех посетивших пользователей c 2023-09-06\n",
    "query = \"\"\"SELECT DISTINCT \n",
    "    toDate(utc_timestamp) AS date, user_id, 1 AS entered,\n",
    "    min(utc_timestamp) AS min_time_entered\n",
    "FROM datamarts.dash_table_distr\n",
    "WHERE created_at != '1970-01-01'\n",
    "    AND ends_at >= '2022-01-01'\n",
    "    AND user_id IS NOT NULL\n",
    "    AND client_type != 'backend'\n",
    "    AND toDate(utc_timestamp) >= '2023-09-06'\n",
    "GROUP BY 1,2,3\n",
    "\"\"\"\n",
    "entered_df = pd.read_sql(query, con=con)\n",
    "entered_df['user_id'] = entered_df['user_id'].astype(str)\n",
    "entered_df['date'] = pd.to_datetime(entered_df['date'])\n",
    "\n",
    "# смотрение с 2023-09-06\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    toDate(utc_timestamp) AS date,\n",
    "    user_id,\n",
    "    CASE\n",
    "        WHEN client_type = 'web_desktop' THEN 'WEB'\n",
    "        WHEN client_type IN ('ios', 'android', 'web_mobile') THEN 'Mobile'\n",
    "        WHEN client_type IN ('Smart TV', 'smart_tv') THEN 'Smart_TV'\n",
    "        ELSE 'Other'\n",
    "    END AS device,\n",
    "    CASE \n",
    "        WHEN event_name = 'auto_player_streaming' AND event_page = 'movie' THEN 'movie'\n",
    "        WHEN event_name = 'auto_player_streaming' AND event_page = 'series' THEN 'series'\n",
    "        WHEN event_name = 'auto_player_streaming' AND event_page = 'tvchannel' THEN 'tv'\n",
    "        WHEN event_name = 'auto_kinom_streaming' THEN 'kinom'\n",
    "        ELSE event_page\n",
    "    END AS event,\n",
    "    SUM(toFloat32OrZero(JSONExtractString(payload, 'viewing_time'))) / 60 AS minutes,\n",
    "    MIN(utc_timestamp) AS min_time_watch\n",
    "FROM datamarts.dash_table_distr\n",
    "WHERE toDate(utc_timestamp) BETWEEN '2023-09-06' AND yesterday()\n",
    "    AND event_name IN ('auto_player_streaming', 'auto_kinom_streaming')\n",
    "    AND event_page IN ('movie', 'series', 'tvchannel', 'main', 'mychannel')\n",
    "    AND user_id IS NOT NULL\n",
    "GROUP BY 1,2,3,4\n",
    "ORDER BY 1,2,3,4\n",
    "\"\"\"\n",
    "watch_df = pd.read_sql(query, con=con)\n",
    "watch_df = preprocess_watching(watch_df)\n",
    "\n",
    "# датасет активности со статусами\n",
    "activity_df = status_df.merge(entered_df, how='left', on=['date', 'user_id'])\n",
    "activity_df['entered'] = activity_df['entered'].fillna(0).astype(int)\n",
    "activity_df = activity_df.merge(watch_df, how='left', on=['date', 'user_id'])\n",
    "activity_df['delta_watch'] = activity_df['min_time_watch'] - activity_df['min_time_entered']\n",
    "activity_df['delta_watch'] = activity_df['delta_watch'].dt.total_seconds() / 60\n",
    "activity_df['delta_watch'] = np.where(activity_df['delta_watch'] > 0, activity_df['delta_watch'], 0)\n",
    "activity_df = activity_df.sort_values(by=['date', 'user_id']).reset_index(drop=True)\n",
    "activity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2497270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count\n",
       "0  2497270"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "con = create_engine(\"postgresql+psycopg2://analytics:cv3uJY-CTq@10.129.0.20:6432/analytics\")\n",
    "con.connect()\n",
    "\n",
    "table_name = \"activity_dash\"\n",
    "activity_df.to_sql(table_name, con, if_exists='replace', index=False)\n",
    "\n",
    "pd.read_sql('SELECT count(*) from public.activity_dash', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
